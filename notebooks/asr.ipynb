{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample loaded: 30.11 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "LANG_ID = \"it\"\n",
    "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-italian\"\n",
    "SAMPLES = 10\n",
    "\n",
    "audio_path = \"../data/sample_short.mp3\"\n",
    "speech_array, sampling_rate = librosa.load(audio_path, sr=16_000)\n",
    "print(f\"Sample loaded: {speech_array.shape[0] / sampling_rate:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Loading model')\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: i greci erano delle creature orrende nella vostra copertina sono rappresentate efficacemente perché quello è un vaso attico ritrovato in grecia iallantichiàma allora concentriamoci un attimo su questa tentazione delle sireemi dite che cosa stanno promettendo di cantare le sirene che cosa dicono di sapere la guerradipaa\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "input_values = processor(speech_array, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "\n",
    "# calculate time\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "end_time = time.time()\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Prediction:\", predicted_sentence)\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Time elapsed: {end_time - start_time:.2f} seconds for a {speech_array.shape[0] / sampling_rate:.2f} seconds audio\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
